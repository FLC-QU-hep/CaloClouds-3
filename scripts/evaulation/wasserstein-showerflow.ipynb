{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8d288535-7dd7-42b4-8fba-0294d9afc786",
   "metadata": {},
   "source": [
    "# Calculate the Wasserstein distance for showerflow models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "04e638ac-47dc-4599-b150-41fa3fcbf552",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found dataset at /data/dust/user/akorol/data/AngularShowers_RegularDetector/hdf5_for_CC/sim-E1261AT600AP180-180_file_{}slcio.hdf5\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from pointcloud.config_varients import caloclouds_3_simple_shower\n",
    "from pointcloud.evaluation import discriminator\n",
    "from pointcloud.utils import showerflow_training, showerflow_utils\n",
    "from pointcloud.utils.metadata import Metadata\n",
    "from pointcloud.utils.plotting import RatioPlots, nice_hex\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "\n",
    "configs = caloclouds_3_simple_shower.Configs()\n",
    "if torch.cuda.is_available():\n",
    "    configs.device = \"cuda\"\n",
    "else:\n",
    "    configs.device = \"cpu\"\n",
    "if os.path.exists(os.path.dirname(configs.dataset_path)):\n",
    "    print(f\"Found dataset at {configs.dataset_path}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38bdab65-9c64-4b58-a46a-3cfbeecc2afb",
   "metadata": {},
   "source": [
    "Get the generator models we will be comparing with, and check their data has been generated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "78a82e5c-e963-4f67-904e-ab5719da9548",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All g4 data files already exist\n"
     ]
    }
   ],
   "source": [
    "discriminator.create_g4_data_files(configs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a069d019-fe63-4699-b907-e9fab533d2f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original_nb4_fnorms_wo[0, 1, 4] has best loss -145.9351401815609\n",
      "alt1_nb4_fnorms_wo[0, 1, 4] has best loss -147.62754416952328\n",
      "Found 10 saved models\n",
      "original_nb4_fnorms_wo[0, 1, 4] has best loss -145.9351401815609\n",
      "alt1_nb4_fnorms_wo[0, 1, 4] has best loss -147.62754416952328\n",
      "Found 10 saved models\n",
      "original_nb4_fnorms_wo[0, 1, 4] has best loss -145.9351401815609\n",
      "alt1_nb4_fnorms_wo[0, 1, 4] has best loss -147.62754416952328\n",
      "Found 10 saved models\n",
      "original_nb4_fnorms_wo[0, 1, 4] has best loss -145.9351401815609\n",
      "alt1_nb4_fnorms_wo[0, 1, 4] has best loss -147.62754416952328\n",
      "Found 10 saved models\n",
      "Found 1 saved models\n",
      "Found 1 saved models\n",
      "Found 1 saved models\n",
      "Found 1 saved models\n",
      "Some /data/dust/user/dayhallh/point-cloud-diffusion-data/showerFlow/sim-E1261AT600AP180-180/ShowerFlow_original_nb2_inputs8070450532247928831_fnorms_best.pth data files are missing; 0/88\n",
      "Creating /data/dust/user/dayhallh/point-cloud-diffusion-data/showerFlow/sim-E1261AT600AP180-180/ShowerFlow_original_nb2_inputs8070450532247928831_fnorms_best.pth data files\n",
      "\n",
      "100%\n",
      "Some /data/dust/user/dayhallh/point-cloud-diffusion-data/showerFlow/sim-E1261AT600AP180-180/ShowerFlow_original_nb4_inputs8070450532247928831_fnorms_best.pth data files are missing; 0/88\n",
      "Creating /data/dust/user/dayhallh/point-cloud-diffusion-data/showerFlow/sim-E1261AT600AP180-180/ShowerFlow_original_nb4_inputs8070450532247928831_fnorms_best.pth data files\n",
      "\n",
      "100%\n",
      "Some /data/dust/user/dayhallh/point-cloud-diffusion-data/showerFlow/sim-E1261AT600AP180-180/ShowerFlow_original_nb6_inputs8070450532247928831_fnorms_best.pth data files are missing; 0/88\n",
      "Creating /data/dust/user/dayhallh/point-cloud-diffusion-data/showerFlow/sim-E1261AT600AP180-180/ShowerFlow_original_nb6_inputs8070450532247928831_fnorms_best.pth data files\n",
      "\n",
      "100%\n",
      "Some /data/dust/user/dayhallh/point-cloud-diffusion-data/showerFlow/sim-E1261AT600AP180-180/ShowerFlow_original_nb8_inputs8070450532247928831_fnorms_best.pth data files are missing; 0/88\n",
      "Creating /data/dust/user/dayhallh/point-cloud-diffusion-data/showerFlow/sim-E1261AT600AP180-180/ShowerFlow_original_nb8_inputs8070450532247928831_fnorms_best.pth data files\n",
      "\n",
      "100%\n",
      "Some /data/dust/user/dayhallh/point-cloud-diffusion-data/showerFlow/sim-E1261AT600AP180-180/ShowerFlow_original_nb10_inputs8070450532247928831_fnorms_best.pth data files are missing; 0/88\n",
      "Creating /data/dust/user/dayhallh/point-cloud-diffusion-data/showerFlow/sim-E1261AT600AP180-180/ShowerFlow_original_nb10_inputs8070450532247928831_fnorms_best.pth data files\n",
      "\n",
      "0%\r"
     ]
    }
   ],
   "source": [
    "existing_list = []\n",
    "for fnorm in [True, False]:\n",
    "    configs.shower_flow_fixed_input_norms = fnorm\n",
    "    for tbase in [True, False]:\n",
    "        configs.shower_flow_train_base = tbase\n",
    "        found_here = showerflow_utils.existing_models(configs)\n",
    "        existing_list.append(showerflow_utils.existing_models(configs))\n",
    "existing_models = {\n",
    "    key: sum([model[key] for model in existing_list], []) for key in existing_list[0]\n",
    "}\n",
    "existing_models[\"configs\"] = []\n",
    "\n",
    "for i, path in enumerate(existing_models[\"paths\"]):\n",
    "    model_configs = showerflow_utils.construct_configs(configs, existing_models, i)\n",
    "    discriminator.create_showerflow_data_files(model_configs, path)\n",
    "    existing_models[\"configs\"].append(model_configs)\n",
    "\n",
    "print(f\"Total models found: {len(existing_models['names'])}\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27bfa916-062c-4642-9f22-06648e27a14a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#table = [['', 'versions', 'num_blocks', 'cut_inputs', 'fixed_input_norms', 'train_base', 'best_loss']]\n",
    "table = [['', 'versions', 'num_blocks', 'cut_inputs', 'fixed_input_norms', 'best_loss']]\n",
    "col_width = 15\n",
    "n_models = len(existing_models['paths'])\n",
    "for i in range(n_models):\n",
    "    table.append([str(i)] + [str(existing_models[k][i]) for k in table[0][1:]])\n",
    "for row in table:\n",
    "    line = \"\"\n",
    "    for col in row:\n",
    "        col = col[:col_width]\n",
    "        col = \" \"*(col_width-len(col)) + col\n",
    "        col += \",\"\n",
    "        line += col\n",
    "    print(line)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a49fa6b-a9ff-4666-bdf0-70aa058c166b",
   "metadata": {},
   "outputs": [],
   "source": [
    "existing_models.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62a40474-ad2f-4c7c-977c-7fd9411aa708",
   "metadata": {},
   "source": [
    "## data fetching\n",
    "\n",
    "The same libraries as were used to train the discriminator make it easy to get Wasserstein distances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7485285-d97a-4406-be02-f3146ee690af",
   "metadata": {},
   "outputs": [],
   "source": [
    "g4_data_folder = discriminator.locate_g4_data(configs)\n",
    "print(f\"g4 data in {g4_data_folder}\")\n",
    "def gen_training(model_idx, settings=\"settings12\"):\n",
    "    model_name = existing_models[\"names\"][model_idx]\n",
    "    model_configs = existing_models[\"configs\"][model_idx]\n",
    "    model_path = existing_models[\"paths\"][model_idx]\n",
    "    model_data_folder = discriminator.locate_model_data(model_configs, model_path)\n",
    "    feature_mask = discriminator.feature_masks[settings]\n",
    "    if not os.path.exists(g4_data_folder):\n",
    "        os.makedirs(g4_data_folder)\n",
    "    if not os.path.exists(model_data_folder):\n",
    "        os.makedirs(model_data_folder)\n",
    "    training = discriminator.Training(settings, g4_data_folder, model_data_folder, discriminator.descriminator_params[settings], feature_mask)\n",
    "    return model_name, training\n",
    "\n",
    "first_model, training = gen_training(15)\n",
    "idxs = [2, 6, 19]\n",
    "print(first_model)\n",
    "\n",
    "\n",
    "g4_test = training._test_dataset.g4_features\n",
    "gen_test = training._test_dataset.generator_features\n",
    "\n",
    "# input dimensions\n",
    "cogs = [0, 1, 2]\n",
    "if training.state_dict[\"feature_mask\"] is not None:\n",
    "    cogs = np.where(training.state_dict[\"feature_mask\"][:3])[0].tolist()\n",
    "\n",
    "n_cogs = len(cogs)\n",
    "n_pnts_layers = 30\n",
    "if training.state_dict[\"feature_mask\"] is not None:\n",
    "    n_pnts_layers = np.sum(training.state_dict[\"feature_mask\"][3:33])\n",
    "    \n",
    "n_es_layers = 30\n",
    "if training.state_dict[\"feature_mask\"] is not None:\n",
    "    n_es_layers = np.sum(training.state_dict[\"feature_mask\"][33:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a72ac150-9b04-4dd2-b874-609bb3f48027",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import wasserstein_distance\n",
    "save_name = os.path.join(showerflow_utils.get_showerflow_dir(configs), \"wasserstein.npz\")\n",
    "if os.path.exists(save_name):\n",
    "    redo = False\n",
    "    loaded = np.load(save_name)\n",
    "    distances_1d = list(loaded[\"Wasserstein_distances\"])\n",
    "else:\n",
    "    redo = True\n",
    "    distances_1d = [np.zeros(n_cogs+n_pnts_layers+n_es_layers) for _ in existing_models[\"paths\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66f716b5-3237-407a-ad35-c6c2bab6ef07",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "total_ticks = n_cogs*n_models\n",
    "if cogs and redo:\n",
    "    for ci, c in enumerate(cogs):\n",
    "        truth = g4_test[:].T[ci]\n",
    "        for i in range(n_models):\n",
    "            percent = (ci*n_models+i)/total_ticks\n",
    "            print(f\"{percent:.1%}\", end=\"\\r\")\n",
    "            name, training = gen_training(i)\n",
    "            gen_test = training._test_dataset.generator_features\n",
    "            gen_data = gen_test[:].T[ci]\n",
    "            distance = wasserstein_distance(truth, gen_data)\n",
    "            distances_1d[i][ci] = distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24710c30-e6aa-48ab-98ec-fb171b5b3b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_ticks = n_pnts_layers*n_models\n",
    "if n_pnts_layers and redo:\n",
    "    for pi, p in enumerate(range(n_cogs, n_cogs+n_pnts_layers)):\n",
    "        truth = g4_test[:].T[pi]\n",
    "        for i in range(n_models):\n",
    "            percent = (pi*n_models+i)/total_ticks\n",
    "            print(f\"{percent:.1%}\", end=\"\\r\")\n",
    "            name, training = gen_training(i)\n",
    "            gen_test = training._test_dataset.generator_features\n",
    "            gen_data = gen_test[:].T[pi]\n",
    "            distance = wasserstein_distance(truth, gen_data)\n",
    "            distances_1d[i][pi+n_cogs] = distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd1b69c1-1569-4a58-85a5-11989874e08e",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_ticks = n_es_layers*n_models\n",
    "if n_es_layers and redo:\n",
    "    for ei, e in enumerate(range(n_cogs+n_pnts_layers, n_cogs+n_pnts_layers+n_es_layers)):\n",
    "        truth = g4_test[:].T[e]\n",
    "        for i in range(n_models):\n",
    "            percent = (ei*n_models+i)/total_ticks\n",
    "            print(f\"{percent:.1%}\", end=\"\\r\")\n",
    "            name, training = gen_training(i)\n",
    "            gen_test = training._test_dataset.generator_features\n",
    "            gen_data = gen_test[:].T[ei]\n",
    "            distance = wasserstein_distance(truth, gen_data)\n",
    "            distances_1d[i][ei] = distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "112d93a2-a933-4638-b9ee-c119596a37c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "if redo:\n",
    "    existing_models[\"Wasserstein_distances\"] = distances_1d\n",
    "    np.savez(save_name, **existing_models)\n",
    "    redo = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ad7fbd4-e899-47a7-ad7c-be80b85c5797",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(existing_models.keys())\n",
    "save_name = os.path.join(showerflow_utils.get_showerflow_dir(configs), \"sliced_wasserstein.npz\")\n",
    "working = list(range(len(existing_models[\"names\"])))\n",
    "n_working = len(working)\n",
    "if os.path.exists(save_name):\n",
    "    loaded = np.load(save_name)\n",
    "    distances = loaded[\"sliced_wasserstein_distances\"]\n",
    "else:\n",
    "    import ot\n",
    "    \n",
    "    g4_test = training._test_dataset.g4_features\n",
    "    n_events = 10000\n",
    "    truth_data = g4_test[:n_events]\n",
    "    n_projections = 1000\n",
    "    n_seeds = 10\n",
    "    distances = np.empty((n_working, n_seeds))\n",
    "    for i, w in enumerate(working):\n",
    "        print(f\"{i/n_working:.1%}\", end=\"\\r\")\n",
    "        try:\n",
    "            name, training = gen_training(w)\n",
    "        except Exception as e:\n",
    "            print()\n",
    "            print(e)\n",
    "            print()\n",
    "            \n",
    "        gen_test = training._test_dataset.generator_features\n",
    "        gen_data = gen_test[:n_events]\n",
    "        for seed in range(n_seeds):\n",
    "            distances[i, seed] = ot.sliced_wasserstein_distance(truth_data, gen_data, n_projections=n_projections, seed=seed)\n",
    "\n",
    "    existing_models[\"sliced_wasserstein_distances\"] = distances\n",
    "    np.savez(save_name, **existing_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef30b26f-e7e3-4193-8dee-2c6b643c1849",
   "metadata": {},
   "outputs": [],
   "source": [
    "del aucs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f9e0847-a3da-416c-b2f5-30f496f353c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 8))\n",
    "cmap = plt.cm.tab10\n",
    "heights = np.linspace(np.min(distances), np.max(distances), n_working)\n",
    "from sklearn import metrics\n",
    "n_models = len(existing_models[\"names\"])\n",
    "\n",
    "try:\n",
    "    len(aucs)\n",
    "except Exception:\n",
    "    aucs = []\n",
    "    for i in range(n_models):\n",
    "        print(f\"{i/n_models}\", end=\"\\r\")             \n",
    "        name, training = gen_training(i)\n",
    "        import ipdb\n",
    "        ipdb.set_trace()\n",
    "        training.reload()\n",
    "        labels, predictions = training.predict_test()\n",
    "        auc = metrics.roc_auc_score(labels, predictions)\n",
    "        aucs.append(auc)\n",
    "\n",
    "for i in range(n_models):\n",
    "    print(f\"{i/n_models}\", end=\"\\r\")\n",
    "    name = existing_models[\"names\"][i].split(\"_wo\")[0]\n",
    "    distance = np.mean(distances[i])\n",
    "    distance_err = np.std(distances[i])              \n",
    "    auc = aucs[i]\n",
    "    c = cmap(i/n_models)\n",
    "    mean_distance = np.mean(distances_1d[i])\n",
    "    max_distance = np.max(distances_1d[i])\n",
    "    ax1.text(auc, mean_distance-0.02, name,\n",
    "             rotation=-20, rotation_mode='anchor',\n",
    "             color=c, size=8\n",
    "            )\n",
    "    n_blocks = existing_models[\"num_blocks\"][w]\n",
    "    ax1.scatter([auc,], [mean_distance,], s=n_blocks, alpha=0.4,\n",
    "             c=c)\n",
    "    ax2.text(auc, max_distance-0.2, name,\n",
    "             rotation=-20, rotation_mode='anchor',\n",
    "             color=c, size=8\n",
    "            )\n",
    "    ax2.scatter([auc,], [max_distance,], s=n_blocks, alpha=0.4,\n",
    "             c=c)\n",
    "\n",
    "ax1.set_ylabel(\"Mean Wasserstein\")\n",
    "ax1.set_xlabel(\"AUC\")\n",
    "ax2.set_ylabel(\"Max Wasserstein\")\n",
    "ax2.set_xlabel(\"AUC\")\n",
    "fig.tight_layout()\n",
    "plt.savefig(\"wasserstein_1d_vs_auc.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41220d00-0342-4880-8884-182cc96235bd",
   "metadata": {},
   "source": [
    "# Plot and compare....\n",
    "\n",
    "TODO...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cda7ec9-cbf8-49df-91d9-cb15e7b5ee0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "match_on = ['versions', 'num_blocks', 'fixed_input_norms', 'train_base']\n",
    "\n",
    "\n",
    "groupings = []\n",
    "for key in match_on:\n",
    "    group_vars = list(set(existing_models[key]))\n",
    "    group = []\n",
    "    for g in group_vars:\n",
    "        here = [i for i, found in enumerate(existing_models[key]) if found == g]\n",
    "        if len(here)>4:\n",
    "            here = [i for i in here if existing_models[\"num_blocks\"][i]<6]\n",
    "        group.append(here)\n",
    "    groupings.append((group_vars, group))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85b594ca-bb94-4f0f-8cd5-d7165cf856b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import ot\n",
    "\n",
    "first_model, training = gen_training(5)\n",
    "print(first_model)\n",
    "\n",
    "g4_test = training._test_dataset.g4_features\n",
    "gen_test = training._test_dataset.generator_features\n",
    "\n",
    "n_events = 10000\n",
    "truth_data = g4_test[:n_events]\n",
    "gen_data = gen_test[:n_events]\n",
    "\n",
    "n_seed = 10\n",
    "n_projections_arr = np.logspace(0, 3, 10, dtype=int)\n",
    "res = np.empty((n_seed, 10))\n",
    "\n",
    "for seed in range(n_seed):\n",
    "    print(f\"seed = {seed}\")\n",
    "    for i, n_projections in enumerate(n_projections_arr):\n",
    "        print(f\"{i/10:.1%}\", end=\"\\r\")\n",
    "        res[seed, i] = ot.sliced_wasserstein_distance(truth_data, gen_data, n_projections=n_projections, seed=seed)\n",
    "    print()\n",
    "\n",
    "res_mean = np.mean(res, axis=0)\n",
    "res_std = np.std(res, axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "373b31f1-a8d5-4a2e-80b6-827a25126880",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "plt.figure(2)\n",
    "plt.plot(n_projections_arr, res_mean, label=\"SWD\")\n",
    "plt.fill_between(n_projections_arr, res_mean - 2 * res_std, res_mean + 2 * res_std, alpha=0.5)\n",
    "plt.legend()\n",
    "plt.xscale('log')\n",
    "plt.xlabel(\"Number of projections\")\n",
    "plt.ylabel(\"Distance\")\n",
    "plt.title('Sliced Wasserstein Distance with 95% confidence interval')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f145290f-861b-42c8-aa03-a81647efb922",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "cmap = plt.cm.tab10\n",
    "heights = np.linspace(np.min(distances), np.max(distances), n_working)\n",
    "\n",
    "for i, w in enumerate(working):\n",
    "    name = existing_models[\"names\"][w].split(\"_wo\")[0]\n",
    "    distance = np.mean(distances[i])\n",
    "    distance_err = np.std(distances[i])\n",
    "    loss = existing_models[\"best_loss\"][w]\n",
    "    c = cmap(i/n_working)\n",
    "    plt.text(loss+0.2, distance, name,\n",
    "             rotation=-20, rotation_mode='anchor',\n",
    "             color=c, size=8\n",
    "            )\n",
    "    n_blocks = existing_models[\"num_blocks\"][w]\n",
    "    plt.plot([loss, loss], [distance-distance_err, distance+distance_err], lw=3,\n",
    "             c=c)\n",
    "\n",
    "plt.ylabel(\"Sliced Wasserstein\")\n",
    "plt.xlabel(\"Best loss\")\n",
    "plt.savefig(\"sliced_wasserstein_vs_loss.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20eb598f-7b90-40fe-ae10-961a2388167e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "cmap = plt.cm.tab10\n",
    "heights = np.linspace(np.min(distances), np.max(distances), n_working)\n",
    "from sklearn import metrics\n",
    "\n",
    "try:\n",
    "    len(aucs)\n",
    "except Exception:\n",
    "    aucs = []\n",
    "    for i in range(n_models):\n",
    "        print(f\"{i/n_models}\", end=\"\\r\")             \n",
    "        name, training = gen_training(i)\n",
    "        training.reload()\n",
    "        labels, predictions = training.predict_test()\n",
    "        auc = metrics.roc_auc_score(labels, predictions)\n",
    "        aucs.append(auc)\n",
    "\n",
    "for i, w in enumerate(working):\n",
    "    print(f\"{i/n_working}\", end=\"\\r\")\n",
    "    name = existing_models[\"names\"][w].split(\"_wo\")[0]\n",
    "    distance = np.mean(distances[i])\n",
    "    distance_err = np.std(distances[i])                \n",
    "    auc = aucs[w]\n",
    "    c = cmap(i/n_working)\n",
    "    plt.text(auc+0.003, distance, name,\n",
    "             rotation=-20, rotation_mode='anchor',\n",
    "             color=c, size=8\n",
    "            )\n",
    "    n_blocks = existing_models[\"num_blocks\"][w]\n",
    "    plt.plot([auc, auc], [distance-distance_err, distance+distance_err], lw=3,\n",
    "             c=c)\n",
    "\n",
    "plt.ylabel(\"Sliced Wasserstein\")\n",
    "plt.xlabel(\"AUC\")\n",
    "plt.savefig(\"sliced_wasserstein_vs_AUC.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8790dae3-9ecc-4def-bdda-5149ea649a90",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "cmap = plt.cm.tab10\n",
    "heights = np.linspace(np.min(distances), np.max(distances), n_working)\n",
    "from sklearn import metrics\n",
    "\n",
    "try:\n",
    "    len(aucs)\n",
    "except Exception:\n",
    "    aucs = []\n",
    "    for i in range(n_models):\n",
    "        print(f\"{i/n_models}\", end=\"\\r\")             \n",
    "        name, training = gen_training(i)\n",
    "        training.reload()\n",
    "        labels, predictions = training.predict_test()\n",
    "        auc = metrics.roc_auc_score(labels, predictions)\n",
    "        aucs.append(auc)\n",
    "\n",
    "for i, w in enumerate(working):\n",
    "    print(f\"{i/n_working}\", end=\"\\r\")\n",
    "    name = existing_models[\"names\"][w].split(\"_wo\")[0]\n",
    "    distance = np.mean(distances[i])\n",
    "    if distance>10:\n",
    "        continue\n",
    "    distance_err = np.std(distances[i])                \n",
    "    auc = aucs[w]\n",
    "    c = cmap(i/n_working)\n",
    "    plt.text(auc+0.003, distance, name,\n",
    "             rotation=-20, rotation_mode='anchor',\n",
    "             color=c, size=8\n",
    "            )\n",
    "    n_blocks = existing_models[\"num_blocks\"][w]\n",
    "    plt.plot([auc, auc], [distance-distance_err, distance+distance_err], lw=3,\n",
    "             c=c)\n",
    "\n",
    "plt.ylabel(\"Sliced Wasserstein\")\n",
    "plt.xlabel(\"AUC\")\n",
    "plt.savefig(\"sliced_wasserstein_vs_AUC_zoom.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "930f93df-4cda-4c77-a391-7e8c4f764d8b",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "897eaa04-48cd-4448-81fa-95578d5b2199",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "cmap = plt.cm.tab10\n",
    "heights = np.linspace(np.min(distances), np.max(distances), n_working)\n",
    "from sklearn import metrics\n",
    "\n",
    "for i, w in enumerate(working):\n",
    "    print(f\"{i/n_working}\", end=\"\\r\")\n",
    "    name = existing_models[\"names\"][w].split(\"_wo\")[0]\n",
    "    distance = np.mean(distances[i])\n",
    "    distance_err = np.std(distances[i])                \n",
    "    mean_dis = np.mean(distances_1d[i])            \n",
    "    std_dis = np.std(distances_1d[i])/10\n",
    "    c = cmap(i/n_working)\n",
    "    plt.text(mean_dis+0.01, distance, name,\n",
    "             rotation=-20, rotation_mode='anchor',\n",
    "             color=c, size=8\n",
    "            )\n",
    "    n_blocks = existing_models[\"num_blocks\"][w]\n",
    "    plt.plot([mean_dis, mean_dis], [distance-distance_err, distance+distance_err], lw=std_dis,\n",
    "             c=c)\n",
    "\n",
    "plt.ylabel(\"Sliced Wasserstein\")\n",
    "plt.xlabel(\"Mean Wasserstein\")\n",
    "plt.savefig(\"wasserstein_comparison.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c4a276c-4647-41c1-98cd-a7486979ddc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "cmap = plt.cm.tab10\n",
    "heights = np.linspace(np.min(distances), np.max(distances), n_working)\n",
    "from sklearn import metrics\n",
    "\n",
    "for i, w in enumerate(working):\n",
    "    print(f\"{i/n_working}\", end=\"\\r\")\n",
    "    name = existing_models[\"names\"][w].split(\"_wo\")[0]\n",
    "    distance = np.mean(distances[i])\n",
    "    if distance > 10:\n",
    "        continue\n",
    "    distance_err = np.std(distances[i])                \n",
    "    mean_dis = np.mean(distances_1d[i])           \n",
    "    std_dis = np.std(distances_1d[i])/10\n",
    "    c = cmap(i/n_working)\n",
    "    plt.text(mean_dis+0.01, distance, name,\n",
    "             rotation=-20, rotation_mode='anchor',\n",
    "             color=c, size=8\n",
    "            )\n",
    "    n_blocks = existing_models[\"num_blocks\"][w]\n",
    "    plt.plot([mean_dis, mean_dis], [distance-distance_err, distance+distance_err], lw=std_dis,\n",
    "             c=c)\n",
    "\n",
    "plt.ylabel(\"Sliced Wasserstein\")\n",
    "plt.xlabel(\"Mean Wasserstein\")\n",
    "plt.savefig(\"wasserstein_comparison_zoom.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8041fca3-648b-4fce-b052-53185b0d7167",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.path.abspath('train_base.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78f1bba5-95c0-475a-843a-c7e2e5e9cd5a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "calogpu",
   "language": "python",
   "name": "calogpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
